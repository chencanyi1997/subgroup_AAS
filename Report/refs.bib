% This file was created with Citavi 6.4.0.35

@proceedings{127201612920162016,
 year = {12/7/2016 - 12/9/2016},
 title = {{2016 IEEE Global Conference on Signal and Information Processing (GlobalSIP)}},
 address = {[S.l.]},
 publisher = {IEEE},
 isbn = {978-1-5090-4545-7}
}


@proceedings{2005conference,
 year = {2005},
 title = {{Conference Record of the Thirty-Ninth Asilomar Conference onSignals, Systems and Computers, 2005}},
 isbn = {1058-6393}
}


@book{2011fixed,
 year = {2011},
 title = {{Fixed-Point Algorithms for Inverse Problems in Science and Engineering}},
 publisher = {Springer}
}


@book{2012selected,
 year = {2012},
 title = {{Selected Works of David Brillinger}},
 publisher = {Springer}
}


@proceedings{2013international,
 year = {2013},
 title = {{International Conference on Machine Learning}}
}


@proceedings{2014international,
 year = {2014},
 title = {{International Conference on Machine Learning}}
}


@proceedings{2016proceedings,
 year = {2016},
 title = {{Proceedings of the forty-eighth annual ACM symposium on Theory of Computing}}
}


@inproceedings{aeron2007on,
 author = {Aeron, Shuchin and Zhao, Manqi and Saligrama, Venkatesh},
 title = {{On sensing capacity of sensor networks for a class of linear observation models}},
 pages = {388--392},
 publisher = {IEEE},
 isbn = {978-1-4244-1197-9},
 booktitle = {{2007 IEEESP 14th Workshop on Statistical Signal Processing}},
 year = {2007},
 address = {Piscataway NJ},
 doi = {10.1109/SSP.2007.4301286},
 file = {fb9e6c78-be7b-4af9-9720-dfeae11cfe49:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\fb9e6c78-be7b-4af9-9720-dfeae11cfe49.pdf:pdf;Aeron, Zhao et al. 8 26 2007 - 8 29 2007 - On sensing capacity of sensor:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Aeron, Zhao et al. 8 26 2007 - 8 29 2007 - On sensing capacity of sensor.pdf:pdf}
}


@proceedings{annualieeecomputerconference2010ieee,
 year = {2010},
 title = {{IEEE International Conference on Communications (ICC), 2010: Cape Town, South Africa, 23-27 May 2010}},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-4244-6402-9},
 institution = {{Annual IEEE Computer Conference} and {IEEE International Conference on Communications} and ICC}
}


@proceedings{annualieeecomputerconference2014ieee,
 year = {2014},
 title = {{IEEE 79th Vehicular Technology Conference (VTC Spring), 2014: 18-21 May 2014, Seoul, Korea ; proceedings ; [including papers of the] Second International Workshop on Vehicular Traffic Management for Smart Cities (VTM 2014)}},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-4799-4482-8},
 institution = {{Annual IEEE Computer Conference} and {IEEE Vehicular Technology Conference} and {VTC Spring} and {International Workshop on Vehicular Traffic Management for Smart Cities (VTM)}}
}


@article{bach2012optimization,
 author = {Bach, Francis and Jenatton, Rodolphe and Mairal, Julien and Obozinski, Guillaume and others},
 year = {2012},
 title = {{Optimization with sparsity-inducing penalties}},
 pages = {1--106},
 volume = {4},
 number = {1},
 journal = {Foundations and Trends{\textregistered} in Machine Learning},
 file = {Bach, Jenatton et al. 2012 - Optimization with sparsity-inducing penalties:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Bach, Jenatton et al. 2012 - Optimization with sparsity-inducing penalties.pdf:pdf}
}


@article{bajwa2007joint,
 author = {Bajwa, W. and Haupt, J. and Sayeed, A. and Nowak, R.},
 year = {2007},
 title = {{Joint Source--Channel Communication for Distributed Estimation in Sensor Networks}},
 pages = {3629--3653},
 volume = {53},
 number = {10},
 issn = {0018-9448},
 journal = {{IEEE Transactions on Information Theory}},
 doi = {10.1109/TIT.2007.904835},
 file = {9e78f06c-b217-48ac-99bb-5ca2aaae16a9:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\9e78f06c-b217-48ac-99bb-5ca2aaae16a9.pdf:pdf;Bajwa, Haupt et al. 2007 - Joint Source-Channel Communication for Distributed:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Bajwa, Haupt et al. 2007 - Joint Source-Channel Communication for Distributed.pdf:pdf}
}


@misc{baron2009distributed,
 abstract = {Compressive sensing is a signal acquisition framework based on the revelation that a small collection of linear projections of a sparse signal contains enough information for stable recovery. In this paper we introduce a new theory for distributed compressive sensing (DCS) that enables new distributed coding algorithms for multi-signal ensembles that exploit both intra- and inter-signal correlation structures. The DCS theory rests on a new concept that we term the joint sparsity of a signal ensemble. Our theoretical contribution is to characterize the fundamental performance limits of DCS recovery for jointly sparse signal ensembles in the noiseless measurement setting; our result connects single-signal, joint, and distributed (multi-encoder) compressive sensing. To demonstrate the efficacy of our framework and to show that additional challenges such as computational tractability can be addressed, we study in detail three example models for jointly sparse signals. For these models, we develop practical algorithms for joint recovery of multiple signals from incoherent projections. In two of our three models, the results are asymptotically best-possible, meaning that both the upper and lower bounds match the performance of our practical algorithms. Moreover, simulations indicate that the asymptotics take effect with just a moderate number of signals. DCS is immediately applicable to a range of problems in sensor arrays and networks.},
 author = {Baron, Dror and Duarte, Marco F. and Wakin, Michael B. and Sarvotham, Shriram and Baraniuk, Richard G.},
 date = {2009},
 title = {{Distributed Compressive Sensing}},
 url = {\url{https://arxiv.org/pdf/0901.3403}},
 file = {ddf6fd6c-2852-41b6-8070-823c0177f9d4:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\ddf6fd6c-2852-41b6-8070-823c0177f9d4.pdf:pdf;Baron, Duarte et al. 2009 - Distributed Compressive Sensing:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Baron, Duarte et al. 2009 - Distributed Compressive Sensing.pdf:pdf}
}


@inproceedings{boufounos20081,
 author = {Boufounos, Petros T. and Baraniuk, Richard G.},
 title = {1-bit compressive sensing},
 pages = {16--21},
 booktitle = {{2008 42nd Annual Conference on Information Sciences and Systems}},
 year = {2008},
 file = {Boufounos, Baraniuk 2008 - 1-bit compressive sensing:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Boufounos, Baraniuk 2008 - 1-bit compressive sensing.pdf:pdf}
}


@inproceedings{braverman2016communication,
 author = {Braverman, Mark and Garg, Ankit and Ma, Tengyu and Nguyen, Huy L. and Woodruff, David P.},
 title = {{Communication lower bounds for statistical estimation problems via a distributed data processing inequality}},
 pages = {1011--1020},
 booktitle = {{Proceedings of the forty-eighth annual ACM symposium on Theory of Computing}},
 year = {2016},
 file = {http://arxiv.org/pdf/1506.07216v3},
 file = {Braverman, Garg et al. 2016 - Communication lower bounds for statistical:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Braverman, Garg et al. 2016 - Communication lower bounds for statistical.pdf:pdf}
}


@article{breiman1995better,
 abstract = {[A new method, called the nonnegative (nn) garrote, is proposed for doing subset regression. It both shrinks and zeroes coefficients. In tests on real and simulated data, it produces lower prediction error than ordinary subset selection. It is also compared to ridge regression. If the regression equations generated by a procedure do not change drastically with small changes in the data, the procedure is called stable. Subset selection is unstable, ridge is very stable, and the nn-garrote is intermediate. Simulation results illustrate the effects of instability on prediction error.]},
 author = {Breiman, Leo},
 year = {1995},
 title = {{Better Subset Regression Using the Nonnegative Garrote}},
 url = {\url{www.jstor.org/stable/1269730}},
 pages = {373},
 volume = {37},
 number = {4},
 issn = {00401706},
 journal = {{Technometrics}},
 doi = {10.2307/1269730}
}


@incollection{brillinger2012generalized,
 author = {Brillinger, David R.},
 title = {{A generalized linear model with ``Gaussian'' regressor variables}},
 pages = {589--606},
 publisher = {Springer},
 booktitle = {{Selected Works of David Brillinger}},
 year = {2012},
 file = {acd02a4d-039c-4894-87df-00822baf337b:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\acd02a4d-039c-4894-87df-00822baf337b.pdf:pdf}
}


@incollection{brillinger2012generalizedb,
 abstract = {A model in which the conditional expected value of a response variate is an unknown nonlinear function of an unknown linear combination of regressor variates is considered. It is shown that in the case that the regressors are stochastic and jointly Gaussian, or are deterministic and quasi-Gaussian, the ordinary least squares estimates provide useful estimates of the coefficients of the linear combination up to an arbitrary multiplier. The cases of both conditional and unconditional inference are investigated.},
 author = {Brillinger, David R.},
 title = {{A Generalized Linear Model With ``Gaussian'' Regressor Variables}},
 pages = {589--606},
 publisher = {Springer},
 isbn = {978-1-4614-1344-8},
 series = {{Selected works in probability and statistics}},
 editor = {Brillinger, David R. and Guttorp, Peter},
 booktitle = {{Selected works of David Brillinger}},
 year = {2012},
 address = {New York},
 doi = {10.1007/978-1-4614-1344-8{\textunderscore }34},
 file = {e5535dc5-165e-4950-a15e-db365a147033:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\e5535dc5-165e-4950-a15e-db365a147033.pdf:pdf;Brillinger 2012 - A Generalized Linear Model:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Brillinger 2012 - A Generalized Linear Model.pdf:pdf;lehmannfest:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\lehmannfest.pdf:pdf}
}


@book{brillinger2012selected,
 year = {2012},
 title = {{Selected Works of David Brillinger}},
 address = {New York},
 publisher = {Springer},
 isbn = {978-1-4614-1344-8},
 series = {{Selected works in probability and statistics}},
 editor = {Brillinger, David R. and Guttorp, Peter}
}


@article{candes2005decoding,
 author = {Candes, Emmanuel J. and Tao, Terence},
 year = {2005},
 title = {{Decoding by linear programming}},
 pages = {4203--4215},
 volume = {51},
 number = {12},
 issn = {0018-9448},
 journal = {{IEEE Transactions on Information Theory}},
 file = {Candes, Tao 2005 - Decoding by linear programming:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Candes, Tao 2005 - Decoding by linear programming.pdf:pdf}
}


@article{candes2006robust,
 author = {Candes, E. J. and Romberg, J. and Tao, T.},
 year = {2006},
 title = {{Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information}},
 pages = {489--509},
 volume = {52},
 number = {2},
 issn = {0018-9448},
 journal = {{IEEE Transactions on Information Theory}},
 doi = {10.1109/TIT.2005.862083},
 file = {01580791:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\01580791.pdf:pdf}
}


@article{candes2006stable,
 author = {Candes, Emmanuel J. and Romberg, Justin K. and Tao, Terence},
 year = {2006},
 title = {{Stable signal recovery from incomplete and inaccurate measurements}},
 pages = {1207--1223},
 volume = {59},
 number = {8},
 journal = {{Communications on Pure and Applied Mathematics: A Journal Issued by the Courant Institute of Mathematical Sciences}},
 file = {http://doi.wiley.com/10.1002/cpa.20124},
 file = {c781309e-e2f5-4580-b21d-938f9ec1f198:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\c781309e-e2f5-4580-b21d-938f9ec1f198:;Candes, Romberg et al:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Candes, Romberg et al. 2006 - Stable signal recovery from incomplete: 2006 - Stable signal recovery from incomplete}
}


@article{candes2007dantzig,
 abstract = {Project Euclid - mathematics and statistics online},
 author = {Candes, Emmanuel and Tao, Terence},
 year = {2007},
 title = {{The Dantzig selector: Statistical estimation when p is much larger than n}},
 url = {\url{https://projecteuclid.org/euclid.aos/1201012958}},
 pages = {2313--2351},
 volume = {35},
 number = {6},
 issn = {0090-5364},
 journal = {{The Annals of Statistics}},
 doi = {10.1214/009053606000001523},
 file = {Candes, Tao 2007 - The Dantzig selector:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Candes, Tao 2007 - The Dantzig selector.pdf:pdf}
}


@misc{chen2018first,
 abstract = {This paper studies distributed estimation and inference for a general statistical problem with a convex loss that could be non-differentiable. For the purpose of efficient computation, we restrict ourselves to stochastic first-order optimization, which enjoys low per-iteration complexity. To motivate the proposed method, we first investigate the theoretical properties of a straightforward Divide-and-Conquer Stochastic Gradient Descent (DC-SGD) approach. Our theory shows that there is a restriction on the number of machines and this restriction becomes more stringent when the dimension 

p

is large. To overcome this limitation, this paper proposes a new multi-round distributed estimation procedure that approximates the Newton step only using stochastic subgradient. The key component in our method is the proposal of a computationally efficient estimator of

\textgreek{S}

$-$1

w

, where

\textgreek{S}

is the population Hessian matrix and

w

is any given vector. Instead of estimating

\textgreek{S}

(or

\textgreek{S}

$-$1

) that usually requires the second-order differentiability of the loss, the proposed First-Order Newton-type Estimator (FONE) directly estimates the vector of interest

\textgreek{S}

$-$1

w

as a whole and is applicable to non-differentiable losses. Our estimator also facilitates the inference for the empirical risk minimizer. It turns out that the key term in the limiting covariance has the form of

\textgreek{S}

$-$1

w

, which can be estimated by FONE.},
 author = {Chen, Xi and Liu, Weidong and Zhang, Yichen},
 date = {2018},
 title = {{First-order Newton-type Estimator for Distributed Estimation and Inference}},
 url = {\url{https://arxiv.org/pdf/1811.11368}},
 file = {1c5e89e9-1bf1-437a-a955-36560cd26ec3:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\1c5e89e9-1bf1-437a-a955-36560cd26ec3.pdf:pdf;Chen, Liu et al. 2018 - First-order Newton-type Estimator for Distributed:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Chen, Liu et al. 2018 - First-order Newton-type Estimator for Distributed.pdf:pdf}
}


@misc{chen2019distributed,
 abstract = {This paper studies distributed estimation and support recovery for high-dimensional linear regression model with heavy-tailed noise. To deal with heavy-tailed noise whose variance can be infinite, we adopt the quantile regression loss function instead of the commonly used squared loss. However, the non-smooth quantile loss poses new challenges to high-dimensional distributed estimation in both computation and theoretical development. To address the challenge, we transform the response variable and establish a new connection between quantile regression and ordinary linear regression. Then, we provide a distributed estimator that is both computationally and communicationally efficient, where only the gradient information is communicated at each iteration. Theoretically, we show that, after a constant number of iterations, the proposed estimator achieves a near-oracle convergence rate without any restriction on the number of machines. Moreover, we establish the theoretical guarantee for the support recovery. The simulation analysis is provided to demonstrate the effectiveness of our method.},
 author = {Chen, Xi and Liu, Weidong and Mao, Xiaojun and Yang, Zhuoyi},
 date = {2019},
 title = {{Distributed High-dimensional Regression Under a Quantile Loss Function}},
 url = {\url{https://arxiv.org/pdf/1906.05741}},
 file = {2ca9270e-7be4-4460-a002-6c2b4f540872:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\2ca9270e-7be4-4460-a002-6c2b4f540872.pdf:pdf;Chen, Liu et al. 2019 - Distributed High-dimensional Regression:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Chen, Liu et al. 2019 - Distributed High-dimensional Regression.pdf:pdf}
}


@incollection{combettes2011proximal,
 author = {Combettes, Patrick L. and Pesquet, Jean-Christophe},
 title = {{Proximal splitting methods in signal processing}},
 pages = {185--212},
 publisher = {Springer},
 booktitle = {{Fixed-point algorithms for inverse problems in science and engineering}},
 year = {2011},
 file = {http://link.springer.com/10.1007/978-1-4419-9569-8_10}
}


@book{cook1998regression,
 author = {Cook, R. Dennis},
 year = {1998},
 title = {Regression Graphics: Ideas for Studying Regressions Through Graphics},
 address = {New York and Chichester},
 publisher = {Wiley},
 isbn = {0471193658},
 series = {{Wiley series in probability and statistics. Probability and statistics section}},
 edition   = {1}
}


@article{dai2016noisy,
 author = {Dai, Dao-Qing and Shen, Lixin and Xu, Yuesheng and Zhang, Na},
 year = {2016},
 title = {{Noisy 1-bit compressive sensing: models and algorithms}},
 pages = {1--32},
 volume = {40},
 number = {1},
 journal = {{Applied and Computational Harmonic Analysis}},
 file = {Dai, Shen et al. 2016 - Noisy 1-bit compressive sensing:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Dai, Shen et al. 2016 - Noisy 1-bit compressive sensing.pdf:pdf}
}


@article{dassios2015preconditioner,
 author = {Dassios, Ioannis and Fountoulakis, Kimon and Gondzio, Jacek},
 year = {2015},
 title = {{A preconditioner for a primal-dual newton conjugate gradient method for compressed sensing problems}},
 pages = {A2783--A2812},
 volume = {37},
 number = {6},
 journal = {{SIAM Journal on Scientific Computing}},
 file = {http://epubs.siam.org/doi/10.1137/141002062},
 file = {Dassios, Fountoulakis et al. 2015 - A preconditioner for a primal-dual:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Dassios, Fountoulakis et al. 2015 - A preconditioner for a primal-dual.pdf:pdf}
}


@article{diaconis1984asymptotics,
 abstract = {Project Euclid - mathematics and statistics online},
 author = {Diaconis, Persi and Freedman, David},
 year = {1984},
 title = {{Asymptotics of graphical projection pursuit}},
 url = {\url{https://projecteuclid.org/euclid.aos/1176346703}},
 pages = {793--815},
 volume = {12},
 number = {3},
 issn = {0090-5364},
 journal = {{The Annals of Statistics}},
 doi = {10.1214/aos/1176346703},
 file = {4452ce6c-a031-4370-ad56-d62493578b90:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\4452ce6c-a031-4370-ad56-d62493578b90.pdf:pdf;Diaconis, Freedman 1984 - Asymptotics of Graphical Projection Pursuit:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Diaconis, Freedman 1984 - Asymptotics of Graphical Projection Pursuit.pdf:pdf}
}


@article{donoho2006compressed,
 author = {Donoho, David L.},
 year = {2006},
 title = {{Compressed sensing}},
 pages = {1289--1306},
 volume = {52},
 number = {4},
 issn = {0018-9448},
 journal = {{IEEE Transactions on Information Theory}},
 file = {Donoho 2006 - Compressed sensing:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Donoho 2006 - Compressed sensing.pdf:pdf}
}


@article{fan2001variable,
 author = {Fan, Jianqing and Li, Runze},
 year = {2001},
 title = {{Variable selection via nonconcave penalized likelihood and its oracle properties}},
 pages = {1348--1360},
 volume = {96},
 number = {456},
 journal = {{Journal of the American Statistical Association}},
 doi = {10.1198/016214501753382273},
 file = {aef2e49a-1801-455c-aa10-bb8ae77e9bb4:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\aef2e49a-1801-455c-aa10-bb8ae77e9bb4.pdf:pdf}
}


@article{fan2014primal,
 author = {Fan, Qibin and Jiao, Yuling and Lu, Xiliang},
 year = {2014},
 title = {{A primal dual active set algorithm with continuation for compressed sensing}},
 pages = {6276--6285},
 volume = {62},
 number = {23},
 journal = {{IEEE Transactions on Signal Processing}},
 file = {Fan, Jiao et al. 2014 - A primal dual active set:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Fan, Jiao et al. 2014 - A primal dual active set.pdf:pdf}
}


@misc{fan2019communicationb,
 abstract = {When the data are stored in a distributed manner, direct application of traditional statistical inference procedures is often prohibitive due to communication cost and privacy concerns. This paper develops and investigates two Communication-Efficient Accurate Statistical Estimators (CEASE), implemented through iterative algorithms for distributed optimization. In each iteration, node machines carry out computation in parallel and communicate with the central processor, which then broadcasts aggregated information to node machines for new updates. The algorithms adapt to the similarity among loss functions on node machines, and converge rapidly when each node machine has large enough sample size. Moreover, they do not require good initialization and enjoy linear converge guarantees under general conditions. The contraction rate of optimization errors is presented explicitly, with dependence on the local sample size unveiled. In addition, the improved statistical accuracy per iteration is derived. By regarding the proposed method as a multi-step statistical estimator, we show that statistical efficiency can be achieved in finite steps in typical statistical applications. In addition, we give the conditions under which the one-step CEASE estimator is statistically efficient. Extensive numerical experiments on both synthetic and real data validate the theoretical results and demonstrate the superior performance of our algorithms.},
 author = {Fan, Jianqing and Guo, Yongyi and Wang, Kaizheng},
 date = {2019},
 title = {{Communication-Efficient Accurate Statistical Estimation}},
 url = {\url{https://arxiv.org/pdf/1906.04870}},
 file = {3829d873-325c-40df-b31b-4161d00afe83:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\3829d873-325c-40df-b31b-4161d00afe83.pdf:pdf;Fan, Guo et al  2019 - Communication-Efficient Accurate Statistical Estimation (2):D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Fan, Guo et al  2019 - Communication-Efficient Accurate Statistical Estimation (2).pdf:pdf}
}


@article{fountoulakis2014matrix,
 author = {Fountoulakis, Kimon and Gondzio, Jacek and Zhlobich, Pavel},
 year = {2014},
 title = {{Matrix-free interior point method for compressed sensing problems}},
 pages = {1--31},
 volume = {6},
 number = {1},
 journal = {{Mathematical Programming Computation}},
 file = {http://link.springer.com/10.1007/s12532-013-0063-6}
}


@article{genzel2019recovering,
 author = {Genzel, Martin and Jung, Peter},
 year = {2019},
 title = {{Recovering structured data from superimposed non-linear measurements}},
 pages = {453--477},
 volume = {66},
 number = {1},
 issn = {0018-9448},
 journal = {{IEEE Transactions on Information Theory}},
 file = {Genzel, Jung 2019 - Recovering structured data from superimposed:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Genzel, Jung 2019 - Recovering structured data from superimposed.pdf:pdf}
}


@inproceedings{gopi2013one,
 author = {Gopi, Sivakant and Netrapalli, Praneeth and Jain, Prateek and Nori, Aditya},
 title = {{One-bit compressed sensing: Provable support and vector recovery}},
 pages = {154--162},
 booktitle = {{International Conference on Machine Learning}},
 year = {2013}
}


@inproceedings{gupta2010sample,
 author = {Gupta, Ankit and Nowak, Robert and Recht, Benjamin},
 title = {{Sample complexity for 1-bit compressed sensing and sparse classification}},
 pages = {1553--1557},
 booktitle = {{2010 IEEE International Symposium on Information Theory}},
 year = {2010}
}


@inproceedings{gupta2015joint,
 author = {Gupta, Vipul and Kailkhura, Bhavya and Wimalajeewa, Thakshila and Liu, Sijia and Varshney, Pramod K.},
 title = {{Joint sparsity pattern recovery with 1-bit compressive sensing in sensor networks}},
 pages = {1472--1476},
 publisher = {IEEE},
 isbn = {978-1-4673-8576-3},
 editor = {Matthews, Michael B.},
 booktitle = {{Conference Record of The Forty-Ninth Asilomar Conference on Signals, Systems {\&} Computers}},
 year = {2015},
 address = {Piscataway, NJ},
 doi = {10.1109/ACSSC.2015.7421389},
 file = {http://ieeexplore.ieee.org/document/7421389/},
 file = {Gupta, Kailkhura et al. 11 8 2015 - 11 11 2015 - Joint sparsity pattern recovery:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Gupta, Kailkhura et al. 11 8 2015 - 11 11 2015 - Joint sparsity pattern recovery.pdf:pdf}
}


@article{hall1993on,
 abstract = {[This paper studies the shapes of low dimensional projections from high dimensional data. After standardization, let x be a p-dimensional random variable with mean zero and identity covariance. For a projection \textgreek{b}'x, |\textgreek{b}| = 1, find another direction b so that the regression curve of b'x against \textgreek{b}'x is as nonlinear as possible. We show that when the dimension of x is large, for most directions \textgreek{b} even the most nonlinear regression is still nearly linear. Our method depends on the construction of a pair of p-dimensional random variables, w1, w2, called the rotational twin, and its density function with respect to the standard normal density. With this, we are able to obtain closed form expressions for measuring deviation from normality and deviation from linearity in a suitable sense of average. As an interesting by-product, from a given set of data we can find simple unbiased estimates of E(f\textgreek{b}'x(t)/\textgreek{f}1(t) - 1)2 and E[ (|E(x $\mid$$ \textgreek{b}, \textgreek{b}'x = t)|2 - t2)f2 \textgreek{b}'x(t)/\textgreek{f}2 1(t)], where \textgreek{f}1 is the standard normal density, f\textgreek{b}'x is the density for \textgreek{b}'x and the {\textquotedbl}E{\textquotedbl} is taken with respect to the uniformly distributed \textgreek{b}. This is achieved without any smoothing and without resorting to any laborious projection procedures such as grand tours. Our result is related to the work of Diaconis and Freedman. The impact of our result on several fronts of data analysis is discussed. For example, it helps establish the validity of regression analysis when the link function of the regression model may be grossly wrong. A further generalization, which replaces \textgreek{b}'x by B'x with B = (\textgreek{b}1,..., \textgreek{b}k) for k randomly selected orthonormal vectors (\textgreek{b}i, i = 1,..., k), helps broaden the scope of application of sliced inverse regression (SIR).]},
 author = {Hall, Peter and Li, Ker-Chau},
 year = {1993},
 title = {{On almost linearity of low dimensional projections from high dimensional data}},
 url = {\url{www.jstor.org/stable/2242265}},
 pages = {867--889},
 volume = {21},
 number = {2},
 issn = {2168-8966},
 journal = {{The Annals of Statistics}},
 file = {61dfb0ee-4d5f-4299-8648-31723f41a93a:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\61dfb0ee-4d5f-4299-8648-31723f41a93a.pdf:pdf;Hall, Li 1993 - On almost Linearity of Low:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Hall, Li 1993 - On almost Linearity of Low.pdf:pdf}
}


@book{hastie2015statistical,
 author = {Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
 year = {2015},
 title = {Statistical Learning with Sparsity: The Lasso and Generalizations},
 price = {{\pounds}57.99},
 address = {Boca Raton},
 edition = {1st},
 publisher = {{Chapman {\&} Hall/CRC}},
 isbn = {9781498712163},
 series = {{Chapman {\&} Hall/CRC monographs on statistics {\&} applied probability}}
}


@inproceedings{haupt2011robust,
 author = {Haupt, Jarvis and Baraniuk, Richard},
 title = {{Robust support recovery using sparse compressive sensing matrices}},
 pages = {1--6},
 booktitle = {{2011 45th Annual Conference on Information Sciences and Systems}},
 year = {2011},
 file = {Haupt, Baraniuk 2011 - Robust support recovery using sparse:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Haupt, Baraniuk 2011 - Robust support recovery using sparse.pdf:pdf}
}


@article{huang2018robust,
 author = {Huang, Jian and Jiao, Yuling and Lu, Xiliang and Zhu, Liping},
 year = {2018},
 title = {{Robust decoding from 1-bit compressive sampling with ordinary and regularized least squares}},
 pages = {A2062--A2086},
 volume = {40},
 number = {4},
 journal = {{SIAM Journal on Scientific Computing}},
 file = {https://epubs.siam.org/doi/10.1137/17M1154102}
}


@proceedings{ieee20082008,
 year = {2008},
 title = {{2008 42nd Annual Conference on Information Sciences and Systems}},
 institution = {IEEE}
}


@proceedings{ieee20102010,
 year = {2010},
 title = {{2010 IEEE International Symposium on Information Theory}},
 institution = {IEEE}
}


@proceedings{ieee20112011,
 year = {2011},
 title = {{2011 45th Annual Conference on Information Sciences and Systems}},
 institution = {IEEE}
}


@proceedings{ieeelassotheory20142014,
 year = {2014},
 title = {{2014 52nd Annual Allerton Conference on Communication, Control, and Computing (Allerton)}},
 institution = {{IEEE  {\%} Lasso theory}}
}


@proceedings{instituteofelectricalandelectronicsengineers20072007,
 year = {2007},
 title = {{2007 IEEESP 14th Workshop on Statistical Signal Processing: Madison, WI, 26-29 August 2007}},
 address = {Piscataway NJ},
 publisher = {IEEE},
 isbn = {978-1-4244-1197-9},
 institution = {{Institute of Electrical and Electronics Engineers}}
}


@book{ito2015inverse,
 author = {Ito, Kazufumi and Jin, Bangti},
 year = {2015},
 title = {{Inverse Problems: Tikhonov Theory and Algorithms}},
 publisher = {{World Scientific}}
}


@article{jacques2013quantized,
 author = {Jacques, Laurent and Degraux, K{\'e}vin and de Vleeschouwer, Christophe},
 year = {2013},
 title = {{Quantized iterative hard thresholding: Bridging 1-bit and high-resolution quantized compressed sensing}},
 journal = {{arXiv preprint arXiv:1305.1786}},
 file = {http://arxiv.org/pdf/1305.1786v1}
}


@article{jacques2013robust,
 author = {Jacques, Laurent and Laska, Jason N. and Boufounos, Petros T. and Baraniuk, Richard G.},
 year = {2013},
 title = {{Robust 1-bit compressive sensing via binary stable embeddings of sparse vectors}},
 pages = {2082--2102},
 volume = {59},
 number = {4},
 issn = {0018-9448},
 journal = {{IEEE Transactions on Information Theory}},
 file = {Jacques, Laska et al. 2013 - Robust 1-bit compressive sensing:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Jacques, Laska et al. 2013 - Robust 1-bit compressive sensing.pdf:pdf}
}


@proceedings{jmlr.org2017proceedings,
 year = {2017},
 title = {{Proceedings of the 34th International Conference on Machine Learning-Volume 70}},
 institution = {{JMLR. org}}
}


@misc{k.b.petersen2012matrix,
 abstract = {Matrix identities, relations and approximations. A desktop reference for quick overview of mathematics of matrices.},
 author = {{K. B. Petersen} and {M. S. Pedersen}},
 year = {2012},
 title = {{The Matrix Cookbook}},
 url = {\url{http://localhost/pubdb/p.php?3274}},
 keywords = {inverse;matrix derivative;Matrix identity;matrix relations},
 publisher = {{Technical University of Denmark}}
}


@article{kafle2019joint,
 author = {Kafle, Swatantra and Gupta, Vipul and Kailkhura, Bhavya and Wimalajeewa, Thakshila and Varshney, Pramod K.},
 year = {2019},
 title = {{Joint Sparsity Pattern Recovery With 1-b Compressive Sensing in Distributed Sensor Networks}},
 pages = {15--30},
 volume = {5},
 number = {1},
 journal = {{IEEE Transactions on Signal and Information Processing over Networks}},
 doi = {10.1109/TSIPN.2018.2838038},
 file = {TSIPN.2018.2838038:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\TSIPN.2018.2838038.pdf:pdf}
}


@article{kafledecentralized,
 author = {Kafle, Swatantra and Kailkhura, Bhavya and Wimalajeewa, Thakshila and Varshney, Pramod K.},
 title = {{Decentralized joint sparsity pattern recovery using 1-bit compressive sensing}},
 pages = {1354--1358},
 doi = {10.1109/GlobalSIP.2016.7906062},
 file = {kafle2016:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\kafle2016.pdf:pdf}
}


@article{knudson2016one,
 author = {Knudson, Karin and Saab, Rayan and Ward, Rachel},
 year = {2016},
 title = {{One-bit compressive sensing with norm estimation}},
 pages = {2748--2758},
 volume = {62},
 number = {5},
 issn = {0018-9448},
 journal = {{IEEE Transactions on Information Theory}},
 doi = {10.1109/TIT.2016.2527637},
 file = {Knudson, Saab et al. 2016 - One-Bit Compressive Sensing With Norm:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Knudson, Saab et al. 2016 - One-Bit Compressive Sensing With Norm.pdf:pdf}
}


@article{laska2011trust,
 author = {Laska, Jason N. and Wen, Zaiwen and Yin, Wotao and Baraniuk, Richard G.},
 year = {2011},
 title = {{Trust, but verify: Fast and accurate signal recovery from 1-bit compressive measurements}},
 pages = {5289--5301},
 volume = {59},
 number = {11},
 journal = {{IEEE Transactions on Signal Processing}},
 file = {Laska, Wen et al. 2011 - Trust, but verify:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Laska, Wen et al. 2011 - Trust, but verify.pdf:pdf}
}


@article{lee2015communication,
 author = {Lee, Jason D. and Sun, Yuekai and Liu, Qiang and Taylor, Jonathan E.},
 year = {2015},
 title = {{Communication-efficient sparse regression: a one-shot approach}},
 journal = {{arXiv preprint arXiv:1503.04337}},
 file = {http://arxiv.org/pdf/1503.04337v3},
 file = {Lee, Sun et al. 2015 - Communication-efficient sparse regression:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Lee, Sun et al. 2015 - Communication-efficient sparse regression.pdf:pdf}
}


@article{li1989regression,
 abstract = {Project Euclid - mathematics and statistics online},
 author = {Li, Ker-Chau and Duan, Naihua},
 year = {1989},
 title = {{Regression Analysis Under Link Violation}},
 url = {\url{https://projecteuclid.org/euclid.aos/1176347254}},
 pages = {1009--1052},
 volume = {17},
 number = {3},
 issn = {0090-5364},
 journal = {{The Annals of Statistics}},
 doi = {10.1214/aos/1176347254},
 file = {9eaf4f13-35af-4f97-8c9b-b2f02b1a4d27:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\9eaf4f13-35af-4f97-8c9b-b2f02b1a4d27.pdf:pdf;Li, Duan 1989 - Regression Analysis Under Link Violation:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Li, Duan 1989 - Regression Analysis Under Link Violation.pdf:pdf}
}


@article{li1991sliced,
 author = {Li, Ker-Chau},
 year = {1991},
 title = {{Sliced inverse regression for dimension reduction}},
 pages = {316--327},
 volume = {86},
 number = {414},
 journal = {{Journal of the American Statistical Association}},
 doi = {10.1080/01621459.1991.10475035},
 file = {c584e25c-ac72-43f5-a68a-6c1c2729d3bf:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\c584e25c-ac72-43f5-a68a-6c1c2729d3bf.pdf:pdf;Li 1991 - Sliced Inverse Regression for Dimension:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Li 1991 - Sliced Inverse Regression for Dimension.pdf:pdf}
}


@article{liu2014similar,
 abstract = {Deterministic sensing matrices are useful, because in practice, the sampler has to be a deterministic matrix. It is quite challenging to design a deterministic sensing matrix with low coherence. In this paper, we consider a more general condition, when the deterministic sensing matrix has high coherence and does not satisfy the restricted isometry property (RIP). A novel algorithm, called the similar sensing matrix pursuit (SSMP), is proposed to reconstruct a K-sparse signal, based on the original deterministic sensing matrix. The proposed algorithm consists of off-line and online processing. The goal of the off-line processing is to construct a similar compact sensing matrix containing as much information as possible from the original sensing matrix. The similar compact sensing matrix has low coherence, which guarantees a perfect reconstruction of the sparse vector with high probability. The online processing begins when measurements arrive, and consists of rough and refined estimation processes. Results from our simulation show that the proposed algorithm obtains much better performance while coping with a deterministic sensing matrix with high coherence compared with the subspace pursuit (SP) and basis pursuit (BP) algorithms.},
 author = {Liu, Jing and Mallick, Mahendra and Han, ChongZhao and Yao, XiangHua and Lian, Feng},
 year = {2014},
 title = {{Similar sensing matrix pursuit: An efficient reconstruction algorithm to cope with deterministic sensing matrix}},
 url = {\url{http://www.sciencedirect.com/science/article/pii/S0165168413003198}},
 pages = {101--110},
 volume = {95},
 issn = {0165-1684},
 journal = {{Signal Processing}},
 doi = {10.1016/j.sigpro.2013.08.009},
 file = {f116bbd9-7bde-4718-821b-4396a4a4df81:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\f116bbd9-7bde-4718-821b-4396a4a4df81.pdf:pdf;Liu, Mallick et al. 2014 - Similar sensing matrix pursuit:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Liu, Mallick et al. 2014 - Similar sensing matrix pursuit.pdf:pdf}
}


@article{liu2015general,
 author = {Liu, Jing and Mallick, Mahendra and Lian, Feng and Han, ChongZhao and Sheng, MingXing and Yao, XiangHua},
 year = {2015},
 title = {{General similar sensing matrix pursuit: An efficient and rigorous reconstruction algorithm to cope with deterministic sensing matrix with high coherence}},
 pages = {150--163},
 volume = {114},
 issn = {0165-1684},
 journal = {{Signal Processing}},
 doi = {10.1016/j.sigpro.2015.03.002},
 file = {20079c8f-f6d9-4c1b-a816-3c3d04ace6cc:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\20079c8f-f6d9-4c1b-a816-3c3d04ace6cc.pdf:pdf;Liu, Mallick et al. 2015 - General similar sensing matrix pursuit:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Liu, Mallick et al. 2015 - General similar sensing matrix pursuit.pdf:pdf}
}


@article{liu2016one,
 author = {Liu, Wenhui and Gong, Da and Xu, Zhiqiang},
 year = {2016},
 title = {{One-bit compressed sensing by greedy algorithms}},
 pages = {169--184},
 volume = {9},
 number = {2},
 journal = {{Numerical Mathematics: Theory, Methods and Applications}},
 file = {https://doi.org/10.4208/nmtma.2016.m1428}
}


@article{liu2017efficient,
 abstract = {We consider the joint sparsity Model 1 (JSM-1) in a decentralized scenario, where a number of sensors are connected through a network and there is no fusion center. A novel algorithm, named distributed compact sensing matrix pursuit (DCSMP), is proposed to exploit the computational and communication capabilities of the sensor nodes. In contrast to the conventional distributed compressed sensing algorithms adopting a random sensing matrix, the proposed algorithm focuses on the deterministic sensing matrices built directly on the real acquisition systems. The proposed DCSMP algorithm can be divided into two independent parts, the common and innovation support set estimation processes. The goal of the common support set estimation process is to obtain an estimated common support set by fusing the candidate support set information from an individual node and its neighboring nodes. In the following innovation support set estimation process, the measurement vector is projected into a subspace that is perpendicular to the subspace spanned by the columns indexed by the estimated common support set, to remove the impact of the estimated common support set. We can then search the innovation support set using an orthogonal matching pursuit (OMP) algorithm based on the projected measurement vector and projected sensing matrix. In the proposed DCSMP algorithm, the process of estimating the common component/support set is decoupled with that of estimating the innovation component/support set. Thus, the inaccurately estimated common support set will have no impact on estimating the innovation support set. It is proven that under the condition the estimated common support set contains the true common support set, the proposed algorithm can find the true innovation set correctly. Moreover, since the innovation support set estimation process is independent of the common support set estimation process, there is no requirement for the cardinality of both sets; thus, the proposed DCSMP algorithm is capable of tackling the unknown sparsity problem successfully.},
 author = {Liu, Jing and Huang, Kaiyu and Zhang, Guoxian},
 year = {2017},
 title = {{An Efficient Distributed Compressed Sensing Algorithm for Decentralized Sensor Network}},
 volume = {17},
 number = {4},
 journal = {{Sensors (Basel, Switzerland)}},
 doi = {10.3390/s17040907},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5426831},
 file = {http://www.ncbi.nlm.nih.gov/pubmed/28425949},
 file = {Liu, Huang et al. 2017 - An Efficient Distributed Compressed Sensing:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Liu, Huang et al. 2017 - An Efficient Distributed Compressed Sensing.pdf:pdf}
}


@inproceedings{m.f.duarte2005distributed,
 author = {{M. F. Duarte} and {S. Sarvotham} and {D. Baron} and {M. B. Wakin} and {R. G. Baraniuk}},
 title = {{Distributed Compressed Sensing of Jointly Sparse Signals}},
 pages = {1537--1541},
 isbn = {1058-6393},
 booktitle = {{Conference Record of the Thirty-Ninth Asilomar Conference onSignals, Systems and Computers, 2005}},
 year = {2005},
 doi = {10.1109/ACSSC.2005.1600024},
 file = {M. F. Duarte, S. Sarvotham et al. 2005 - Distributed Compressed Sensing of Jointly:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\M. F. Duarte, S. Sarvotham et al. 2005 - Distributed Compressed Sensing of Jointly.pdf:pdf}
}


@book{mallat1999wavelet,
 author = {Mallat, St{\'e}phane},
 year = {1999},
 title = {{A Wavelet Tour of Signal Processing}},
 publisher = {Elsevier}
}


@article{maly2019analysis,
 author = {Maly, Johannes and Palzer, Lars},
 year = {2019},
 title = {{Analysis of hard-thresholding for distributed compressed sensing with one-bit measurements}},
 journal = {{Information and Inference: A Journal of the IMA}},
 doi = {10.1093/imaiai/iaz004},
 file = {Analysis of hard-thresholding for distributed compressed sensing with one-bit measurements:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Analysis of hard-thresholding for distributed compressed sensing with one-bit measurements.pdf:pdf}
}


@article{matamoros2015distributed,
 author = {Matamoros, Javier and Fosson, Sophie M. and Magli, Enrico and Anton-Haro, Carles},
 year = {2015},
 title = {{Distributed ADMM for In-Network Reconstruction of Sparse Signals With Innovations}},
 pages = {225--234},
 volume = {1},
 number = {4},
 journal = {{IEEE Transactions on Signal and Information Processing over Networks}},
 doi = {10.1109/TSIPN.2015.2497087},
 file = {b69d2856-0654-4105-b13d-ad3efd05ae19:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\b69d2856-0654-4105-b13d-ad3efd05ae19.pdf:pdf;Matamoros, Fosson et al. 2015 - Distributed ADMM for In-Network Reconstruction:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Matamoros, Fosson et al. 2015 - Distributed ADMM for In-Network Reconstruction.pdf:pdf}
}


@article{mateyneykov2016l1,
 author = {{Matey Neykov} and {Jun S. Liu} and {Tianxi Cai}},
 year = {2016},
 title = {{L1-Regularized Least Squares for Support Recovery of High Dimensional Single Index Models with Gaussian Designs}},
 pages = {1--37},
 volume = {17},
 number = {87},
 issn = {1533-7928},
 journal = {{Journal of Machine Learning Research}},
 file = {16-006:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\16-006.pdf:pdf}
}


@proceedings{matthews2015conference,
 year = {2015},
 title = {{Conference Record of The Forty-Ninth Asilomar Conference on Signals, Systems {\&} Computers: November 8-11, 2015, Pacific Grove, California}},
 address = {Piscataway, NJ},
 publisher = {IEEE},
 isbn = {978-1-4673-8576-3},
 editor = {Matthews, Michael B.}
}


@article{michaeli.jordan2019communication,
 author = {{Michael I. Jordan} and {Jason D. Lee} and {Yun Yang}},
 year = {2019},
 title = {{Communication-Efficient Distributed Statistical Inference}},
 pages = {668--681},
 volume = {114},
 number = {526},
 journal = {{Journal of the American Statistical Association}},
 file = {https://www.tandfonline.com/doi/full/10.1080/01621459.2018.1429274}
}

@ARTICLE{mingyuan2006model,
    author = {Ming Yuan and Yi Lin},
    title = {Model selection and estimation in regression with grouped variables},
    journal = {JOURNAL OF THE ROYAL STATISTICAL SOCIETY, SERIES B},
    year = {2006},
    volume = {68},
    pages = {49--67}
}


@article{negahban2012unified,
 author = {Negahban, Sahand N. and Ravikumar, Pradeep and Wainwright, Martin J. and Yu, Bin and others},
 year = {2012},
 title = {{A unified framework for high-dimensional analysis of  M -estimators with decomposable regularizers}},
 pages = {538--557},
 volume = {27},
 number = {4},
 journal = {{Statistical Science}},
 file = {http://projecteuclid.org/euclid.ss/1356098555#supplemental}
}


@article{neiswanger2013asymptotically,
 author = {Neiswanger, Willie and Wang, Chong and Xing, Eric},
 year = {2013},
 title = {{Asymptotically exact, embarrassingly parallel MCMC}},
 journal = {{arXiv preprint arXiv:1311.4780}},
 file = {Neiswanger, Wang et al. 2013 - Asymptotically exact:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Neiswanger, Wang et al. 2013 - Asymptotically exact.pdf:pdf}
}


@article{plan2012robust,
 author = {Plan, Yaniv and Vershynin, Roman},
 year = {2012},
 title = {{Robust 1-bit compressed sensing and sparse logistic regression: A convex programming approach}},
 pages = {482--494},
 volume = {59},
 number = {1},
 issn = {0018-9448},
 journal = {{IEEE Transactions on Information Theory}},
 file = {Plan, Vershynin 2012 - Robust 1-bit compressed sensing:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Plan, Vershynin 2012 - Robust 1-bit compressed sensing.pdf:pdf}
}


@article{plan2013one,
 author = {Plan, Yaniv and Vershynin, Roman},
 year = {2013},
 title = {{One-Bit Compressed Sensing by Linear Programming}},
 pages = {1275--1297},
 volume = {66},
 number = {8},
 journal = {{Communications on Pure and Applied Mathematics}},
 file = {http://doi.wiley.com/10.1002/cpa.21442}
}


@article{plan2017high,
 author = {Plan, Yaniv and Vershynin, Roman and Yudovina, Elena},
 year = {2017},
 title = {{High-dimensional estimation with geometric constraints}},
 pages = {1--40},
 volume = {6},
 number = {1},
 journal = {{Information and Inference: A Journal of the IMA}},
 file = {Plan, Vershynin et al. 2017 - High-dimensional estimation with geometric constraints:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Plan, Vershynin et al. 2017 - High-dimensional estimation with geometric constraints.pdf:pdf}
}


@inproceedings{shamir2014communication,
 author = {Shamir, Ohad and Srebro, Nati and Zhang, Tong},
 title = {{Communication-efficient distributed optimization using an approximate newton-type method}},
 pages = {1000--1008},
 booktitle = {{International Conference on Machine Learning}},
 year = {2014},
 file = {Shamir, Srebro et al. 2014 - Communication-efficient distributed optimization using:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Shamir, Srebro et al. 2014 - Communication-efficient distributed optimization using.pdf:pdf}
}


@inproceedings{shamir2014distributed,
 author = {Shamir, Ohad and Srebro, Nathan},
 title = {{Distributed stochastic optimization and learning}},
 pages = {850--857},
 booktitle = {{2014 52nd Annual Allerton Conference on Communication, Control, and Computing (Allerton)}},
 year = {2014},
 file = {Shamir, Srebro 2014 - Distributed stochastic optimization and learning:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Shamir, Srebro 2014 - Distributed stochastic optimization and learning.pdf:pdf}
}


@article{stein1981estimation,
 abstract = {Project Euclid - mathematics and statistics online},
 author = {Stein, Charles M.},
 year = {1981},
 title = {{Estimation of the Mean of a Multivariate Normal Distribution}},
 url = {\url{https://projecteuclid.org/euclid.aos/1176345632}},
 pages = {1135--1151},
 volume = {9},
 number = {6},
 issn = {0090-5364},
 journal = {{The Annals of Statistics}},
 doi = {10.1214/aos/1176345632},
 file = {1fa9dac6-8d85-4d74-a954-abfcf51f6a99:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\1fa9dac6-8d85-4d74-a954-abfcf51f6a99.pdf:pdf;Stein 1981 - Estimation of the Mean:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Stein 1981 - Estimation of the Mean.pdf:pdf}
}


@article{sundman2016design,
 author = {Sundman, Dennis and Chatterjee, Saikat and Skoglund, Mikael},
 year = {2016},
 title = {{Design and Analysis of a Greedy Pursuit for Distributed Compressed Sensing}},
 pages = {2803--2818},
 volume = {64},
 number = {11},
 issn = {1053-587X},
 journal = {{IEEE Transactions on Signal Processing}},
 doi = {10.1109/TSP.2016.2523462},
 file = {Sundman, Chatterjee et al. 2016 - Design and Analysis:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Sundman, Chatterjee et al. 2016 - Design and Analysis.pdf:pdf}
}


@inproceedings{tian2014distributed,
 author = {Tian, Yun and Xu, Wenbo and Wang, Yue and Yang, Hongwen},
 title = {{A Distributed Compressed Sensing Scheme Based on One-Bit Quantization}},
 pages = {1--6},
 publisher = {IEEE},
 isbn = {978-1-4799-4482-8},
 booktitle = {{IEEE 79th Vehicular Technology Conference (VTC Spring), 2014}},
 year = {2014},
 address = {Piscataway, NJ},
 doi = {10.1109/VTCSpring.2014.7022772},
 file = {http://ieeexplore.ieee.org/document/7022772/},
 file = {tian2014:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\tian2014.pdf:pdf}
}


@article{tibshirani1996regression,
 author = {Tibshirani, Robert},
 year = {1996},
 title = {{Regression shrinkage and selection via the Lasso}},
 pages = {267--288},
 volume = {58},
 number = {1},
 issn = {00359246},
 journal = {{Journal of the Royal Statistical Society: Series B (Methodological)}},
 file = {lasso_2:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\lasso_2.pdf:pdf}
}


@article{tropp2010computational,
 author = {Tropp, Joel A. and Wright, Stephen J.},
 year = {2010},
 title = {{Computational methods for sparse solution of linear inverse problems}},
 pages = {948--958},
 volume = {98},
 number = {6},
 journal = {{Proceedings of the IEEE}},
 file = {Tropp, Wright 2010 - Computational methods for sparse solution:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Tropp, Wright 2010 - Computational methods for sparse solution.pdf:pdf}
}


@book{vershynin2018high,
 author = {Vershynin, Roman},
 year = {2018},
 title = {High-Dimensional Probability: An Introduction with Applications in Data Science},
 price = {{\pounds}48.00},
 address = {Cambridge},
 volume = {47},
 publisher = {Cambridge University Press},
 isbn = {9781108246255},
 series = {{Cambridge series in statistical and probabilistic mathematics}},
 file = {[Roman_Vershynin]_High-Dimensional_Probability(z-lib.org):D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\[Roman_Vershynin]_High-Dimensional_Probability(z-lib.org).pdf:pdf}
}


@article{wainwright2009sharp,
 author = {Wainwright, Martin J.},
 year = {2009},
 title = {{Sharp thresholds for high-Dimensional and noisy sparsity recovery using  $\ell_1$-constrained quadratic programming (Lasso)}},
 pages = {2183--2202},
 volume = {55},
 number = {5},
 issn = {0018-9448},
 journal = {{IEEE Transactions on Information Theory}},
 file = {Wainwright 2009 - Sharp thresholds for High-Dimensional:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Wainwright 2009 - Sharp thresholds for High-Dimensional.pdf:pdf}
}


@article{wang2013parallelizing,
 author = {Wang, Xiangyu and Dunson, David B.},
 year = {2013},
 title = {{Parallelizing MCMC via Weierstrass sampler}},
 journal = {{arXiv preprint arXiv:1312.4605}},
 file = {Wang, Dunson 2013 - Parallelizing MCMC via Weierstrass sampler:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Wang, Dunson 2013 - Parallelizing MCMC via Weierstrass sampler.pdf:pdf}
}


@inproceedings{wang2017efficient,
 author = {Wang, Jialei and Kolar, Mladen and Srebro, Nathan and Zhang, Tong},
 title = {{Efficient distributed learning with sparsity}},
 pages = {3636--3645},
 booktitle = {{Proceedings of the 34th International Conference on Machine Learning-Volume 70}},
 year = {2017},
 file = {2017]Efficient distributed learning with sparsity:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\2017]Efficient distributed learning with sparsity.pdf:pdf;2017]Efficient distributed learning with sparsity_supp:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\2017]Efficient distributed learning with sparsity_supp.pdf:pdf;Wang, Kolar et al. 2017 - Efficient distributed learning with sparsity:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Wang, Kolar et al. 2017 - Efficient distributed learning with sparsity.pdf:pdf}
}


@article{yan2012robust,
 author = {Yan, Ming and Yang, Yi and Osher, Stanley},
 year = {2012},
 title = {{Robust 1-bit compressive sensing using adaptive outlier pursuit}},
 pages = {3868--3875},
 volume = {60},
 number = {7},
 journal = {{IEEE Transactions on Signal Processing}},
 file = {Yan, Yang et al. 2012 - Robust 1-bit compressive sensing using:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Yan, Yang et al. 2012 - Robust 1-bit compressive sensing using.pdf:pdf}
}


@article{yuan2006model,
 author = {Yuan, Ming and Lin, Yi},
 year = {2006},
 title = {{Model selection and estimation in regression with grouped variables}},
 pages = {49--67},
 volume = {68},
 number = {1},
 issn = {1369-7412},
 journal = {{Journal of the Royal Statistical Society: Series B (Statistical Methodology)}},
 doi = {10.1111/j.1467-9868.2005.00532.x}
}


@inproceedings{zeng2010distributed,
 author = {Zeng, F. and Tian, Z. and Li, C.},
 title = {{Distributed Compressive Wideband Spectrum Sensing in Cooperative Multi-Hop Cognitive Networks}},
 pages = {1--5},
 publisher = {IEEE},
 isbn = {978-1-4244-6402-9},
 booktitle = {{IEEE International Conference on Communications (ICC), 2010}},
 year = {2010},
 address = {Piscataway, NJ},
 doi = {10.1109/ICC.2010.5502793},
 file = {e18662bf-f796-4e37-8635-a93e4738ef00:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\e18662bf-f796-4e37-8635-a93e4738ef00.pdf:pdf}
}


@article{zhang2010nearly,
 abstract = {[We propose MC+, a fast, continuous, nearly unbiased and accurate method of penalized variable selection in high-dimensional linear regression. The LASSO is fast and continuous, but biased. The bias of the LASSO may prevent consistent variable selection. Subset selection is unbiased but computationally costly. The MC+ has two elements: a minimax concave penalty (MCP) and a penalized linear unbiased selection (PLUS) algorithm. The MCP provides the convexity of the penalized loss in sparse regions to the greatest extent given certain thresholds for variable selection and unbiasedness. The PLUS computes multiple exact local minimizers of a possibly nonconvex penalized loss function in a certain main branch of the graph of critical points of the penalized loss. Its output is a continuous piecewise linear path encompassing from the origin for infinite penalty to a least squares solution for zero penalty. We prove that at a universal penalty level, the MC+ has high probability of matching the signs of the unknowns, and thus correct selection, without assuming the strong irrepresentable condition required by the LASSO. This selection consistency applies to the case of p $\gg$ n, and is proved to hold for exactly the MC+ solution among possibly many local minimizers. We prove that the MC+ attains certain minimax convergence rates in probability for the estimation of regression coefficients in l r balls. We use the SURE method to derive degrees of freedom and C p -type risk estimates for general penalized LSE, including the LASSO and MC+ estimators, and prove their unbiasedness. Based on the estimated degrees of freedom, we propose an estimator of the noise level for proper choice of the penalty level. For full rank designs and general sub-quadratic penalties, we provide necessary and sufficient conditions for the continuity of the penalized LSE. Simulation results overwhelmingly support our claim of superior variable selection properties and demonstrate the computational efficiency of the proposed method.]},
 author = {Zhang, Cun-Hui},
 year = {2010},
 title = {Nearly unbiased variable selection under minimax concave penalty},
 url = {www.jstor.org/stable/25662264},
 pages = {894--942},
 volume = {38},
 number = {2},
 issn = {2168-8966},
 journal = {{The Annals of Statistics}},
 file = {55ef54ac-5455-4a30-97f0-9f520408da60:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\55ef54ac-5455-4a30-97f0-9f520408da60.pdf:pdf}
}


@article{zhang2013communication,
 author = {Zhang, Yuchen and Duchi, John C. and Wainwright, Martin J.},
 year = {2013},
 title = {{Communication-efficient algorithms for statistical optimization}},
 pages = {3321--3363},
 volume = {14},
 number = {1},
 journal = {{The Journal of Machine Learning Research}},
 file = {zhang13b:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\zhang13b.pdf:pdf}
}


@inproceedings{zhang2014efficient,
 author = {Zhang, Lijun and Yi, Jinfeng and Jin, Rong},
 title = {{Efficient algorithms for robust one-bit compressive sensing}},
 pages = {820--828},
 booktitle = {{International Conference on Machine Learning}},
 year = {2014},
 file = {zhangc14:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\zhangc14.pdf:pdf}
}


@article{zhu2009on,
 author = {Zhu, Li-Ping and Zhu, Li-Xing},
 year = {2009},
 title = {{On distribution-weighted partial least squares with diverging number of highly correlated predictors}},
 pages = {525--548},
 volume = {71},
 number = {2},
 issn = {1369-7412},
 journal = {{Journal of the Royal Statistical Society: Series B (Statistical Methodology)}},
 doi = {10.1111/j.1467-9868.2008.00697.x},
 file = {0cc6a8d0-7de5-4378-83c2-fb199a660236:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\0cc6a8d0-7de5-4378-83c2-fb199a660236.pdf:pdf;Zhu, Zhu 2009 - On distribution-weighted partial least squares:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Zhu, Zhu 2009 - On distribution-weighted partial least squares.pdf:pdf}
}


@article{zhu2011model,
 abstract = {With the recent explosion of scientific data of unprecedented size and complexity, feature ranking and screening are playing an increasingly important role in many scientific studies. In this article, we propose a novel feature screening procedure under a unified model framework, which covers a wide variety of commonly used parametric and semiparametric models. The new method does not require imposing a specific model structure on regression functions, and thus is particularly appealing to ultrahigh-dimensional regressions, where there are a huge number of candidate predictors but little information about the actual model forms. We demonstrate that, with the number of predictors growing at an exponential rate of the sample size, the proposed procedure possesses consistency in ranking, which is both useful in its own right and can lead to consistency in selection. The new procedure is computationally efficient and simple, and exhibits a competent empirical performance in our intensive simulations and real data analysis.},
 author = {Zhu, Liping and Li, Lexin and Li, Runze and Zhu, Lixing},
 year = {2011},
 title = {{Model-Free Feature Screening for Ultrahigh Dimensional Data}},
 pages = {1464--1475},
 volume = {106},
 number = {496},
 journal = {{Journal of the American Statistical Association}},
 doi = {10.1198/jasa.2011.tm10563},
 file = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3384506},
 file = {f04b7d94-2389-4f94-8c23-86eaad3efd33:C\:\\Users\\chencanyi\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\e9ae18f8-8790-42fe-a572-1d074085d20d\\Remote Attachments\\f04b7d94-2389-4f94-8c23-86eaad3efd33.pdf:pdf}
}


@article{zymnis2009compressed,
 author = {Zymnis, Argyrios and Boyd, Stephen and Candes, Emmanuel},
 year = {2009},
 title = {{Compressed sensing with quantized measurements}},
 pages = {149--152},
 volume = {17},
 number = {2},
 journal = {{IEEE Signal Processing Letters}},
 file = {Zymnis, Boyd et al. 2009 - Compressed sensing with quantized measurements:D\:\\Distributed1bit\\citavi\\Distributed1bit\\Citavi Attachments\\Zymnis, Boyd et al. 2009 - Compressed sensing with quantized measurements.pdf:pdf}
}


% for aas
@article{Ma2015ACP,
  title={A Concave Pairwise Fusion Approach to Subgroup Analysis},
  author={Shujie Ma and Jian Huang},
  journal={Journal of the American Statistical Association},
  year={2015},
  volume={112},
  pages={410-423}
}

@article{Wang2011Ckmeans1ddpOK,
  title={Ckmeans.1d.dp: Optimal k-means Clustering in One Dimension by Dynamic Programming.},
  author={Haizhou Wang and Mingzhou Song},
  journal={The R journal},
  year={2011},
  volume={3 2},
  pages={
          29-33
        }
}

@article{Aloise2009NPhardnessOE,
  title={NP-hardness of Euclidean sum-of-squares clustering},
  author={Daniel Aloise and Amit Deshpande and Pierre Hansen and Preyas Popat},
  journal={Machine Learning},
  year={2009},
  volume={75},
  pages={245-248}
}

@inproceedings{Llyod1982LeastSQ,
  title={Least squares quantization in pcm},
  author={S. P. Llyod},
  year={1982}
}

@article{Tsuboi2007ThePS,
  title={The present status of postoperative adjuvant chemotherapy for completely resected non-small cell lung cancer.},
  author={Masahiro Tsuboi and Tatsuo Ohira and Hisashi Saji and Kuniharu Miyajima and Naohiro Kajiwara and Osamu Uchida and Jitsuo Usuda and Harubumi Kato},
  journal={Annals of thoracic and cardiovascular surgery : official journal of the Association of Thoracic and Cardiovascular Surgeons of Asia},
  year={2007},
  volume={13 2},
  pages={
          73-7
        }
}

@article{Orenstein2012RevolutionIL,
  title={Revolution in lung cancer: new challenges for the surgical pathologist.},
  author={Jan Orenstein},
  journal={Archives of pathology \& laboratory medicine},
  year={2012},
  volume={136 2},
  pages={
          138
        }
}

@article{Lee2015IdentifyingAA,
  title={Identifying and Assessing Interesting Subgroups in a Heterogeneous Population},
  author={Woojoo Lee and Andrey Alexeyenko and Maria Pernemalm and Justine Gu{\'e}gan and Philippe Dessen and Vladimir Lazar and Janne Lehti{\"o} and Yudi Pawitan},
  journal={BioMed Research International},
  year={2015},
  volume={2015}
}